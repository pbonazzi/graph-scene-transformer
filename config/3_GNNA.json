{
  "author": "",
  "device": "gpu",
  "output_dir": "output/final/0705/GNNA",

  "inference": false,
  "use_prior": false,
  "inference_scene": "",

  "data": {
    "threed_ssg_subset": 1,
    "threed_ssg_full": 0,
    "checkpoints_path": "output/final/GNNA",
    "temp":"",
    "n_of_relationships_type" : 44,
    "n_of_objects_type": 529,
    "n_of_orientation_bins": 24,
    "graphormer": false,

    "make_full_graph": false,
    "edge_feat": true,
    "floor_plan_bb": true,
    "floor_plan_pc": false,
    "pe": {
          "lap_pe": true,
          "wl_pe": false,
          "pe_dim": 4
    },

    "normalize_location": true,
    "normalize_dimension": true,
    "normalize_orientation": false
  },

  "tests": {
    "max_time": 24,
    "overfit": false,
    "warnings" : false,
    "normalization" : false,
    "deterministic": false
  },

  "params": {
    "seed": 41,
    "epochs": 200,
    "batch_size": 64,
    "n_epochs_stop": 5,

    "render": {
      "download_scan": false,
      "tensorboard_specific_scene": [true, "f62fd5fd-9a3f-2f44-883a-1e5cf819608e"],
      "tensorboard_representation" : "box"
    },


    "encoder": {
      "graph_convolution": true,
      "n_of_convolution_layers": 4,
      "hidden_dimension": 128,
      "input_embedding": {
        "object_code": 23,
        "rotation_z": 23,
        "size": 23,
        "translation": 23
      },
      "symmetryQK": false,
      "n_of_transformers_layers": 2,
      "n_of_attention_heads": 8,
      "residual": true,
      "layer_norm": true,
      "batch_norm": false,
      "types_of_attention": {
        "classic": true,
        "dgl_tutorial": false,
        "as_in_generalization_graph_to_transformer": false,
        "as_in_generalization_graph_to_transformer_on_dst": false,
        "node_edge_combined": false
      }
    },

    "decoder": {
      "graph_convolution": true,
      "n_of_convolution_layers": 4,
      "hidden_dimension": 128,
      "input_scene_graph": true,
      "input_embedding": {
        "object_code": 23
      },
      "output_object_code": false,
      "use_transformer_decoder": true,
      "symmetryQK": false,
      "n_of_transformers_layers": 2,
      "n_of_attention_heads": 8,
      "residual": true,
      "layer_norm": true,
      "batch_norm": false,
      "types_of_attention": {
        "classic": true,
        "dgl_tutorial": false,
        "as_in_generalization_graph_to_transformer": false,
        "as_in_generalization_graph_to_transformer_on_dst": false,
        "node_edge_combined": false
      }
    },

    "multi_layer_loss": false,
    "weight_KLD_loss": 0.01,
    "orientation_loss": true,

    "optimizer": {
      "init_lr": 5e-4,
      "min_lr": 0.0,
      "weight_decay": 0.0,
      "betas": [0.9, 0.98]
    },

    "scheduler": {
      "Noam": false,
      "warmup_steps": 10,
      "ReduceLROnPlateau": true,
      "lr_reduce_factor": 0.99,
      "lr_schedule_patience": 5
    },

    "gradient_clipping" : true,
    "clipping_value" : 5,

    "in_feat_dropout": 0.0,
    "dropout": 0.0

    }
}
